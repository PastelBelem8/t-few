{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329d4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb1cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_instance_level_correlation(data: pd.DataFrame, metrics: list, target_col: str, corr_method: callable) -> dict:\n",
    "    name = corr_method.__name__\n",
    "    print(\"Computing\", name, \"with\", target_col, \"col\")\n",
    "    \n",
    "    # Pseudo algorithm\n",
    "    # 1. Iterate over each doc_id\n",
    "    # 2. Compute the correlation between different metric values for each doc_id and the human values\n",
    "    # 3. Avg correlation coefficients in the end\n",
    "    instance_level_corrs = defaultdict(list)\n",
    "\n",
    "    for iid in data[\"bartscore_doc_id\"].unique():\n",
    "        for m in metrics:\n",
    "            instance = data[data[\"bartscore_doc_id\"] == iid]\n",
    "            corr, p_val = corr_method(instance[m], instance[target_col])\n",
    "            instance_level_corrs[m].append(corr)\n",
    "           \n",
    "    # Compute the avg (#TODO - handle p_val)\n",
    "    instance_level_corrs_avg = {metric: np.mean(corr_data) for metric, corr_data in instance_level_corrs.items()}\n",
    "    return instance_level_corrs_avg\n",
    "\n",
    "\n",
    "def compute_instance_level_correlations(data, metrics, target_col, dataset_name, output_dir, to_persist=True, **_):\n",
    "    correlations = {}\n",
    "    for corr_method in (pearsonr, spearmanr, kendalltau):\n",
    "        result = _get_instance_level_correlation(data, metrics, target_col, corr_method)\n",
    "\n",
    "        correlations[corr_method.__name__] = result\n",
    "\n",
    "    correlations = pd.DataFrame(correlations)\n",
    "    if to_persist:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        correlations.reset_index().to_csv(f\"{output_dir}/{dataset_name}_instance_corrs.csv\", index=0)\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def _get_system_level_correlation(data, metrics, target_col, systems, corr_method: callable) -> dict:\n",
    "    # pseudo code\n",
    "    # for each system\n",
    "    # compute the mean score attributed by a metric m to the outputs of each system.\n",
    "    # compute the mean score attributed by a target_col to the outputs of each system.\n",
    "    # compute correlation\n",
    "    system_level_correlation = defaultdict(list)\n",
    "    for sys in systems:\n",
    "        data_sys = data[data[\"sys_name\"] == sys]\n",
    "        # ^Note: since we're computing the mean, we dont need to ensure the ordering\n",
    "\n",
    "        for m in metrics + [target_col]:\n",
    "            mean_sys = data_sys[m].mean()\n",
    "            system_level_correlation[m].append(mean_sys)\n",
    "\n",
    "    # Compute the correlation now\n",
    "    correlations = {}\n",
    "    for m in metrics:\n",
    "        corr, p_val = corr_method(system_level_correlation[m], system_level_correlation[target_col])\n",
    "\n",
    "        correlations[m] = round(corr, 4)\n",
    "\n",
    "    return correlations\n",
    "\n",
    "\n",
    "def compute_system_level_correlations(data, metrics, target_col, dataset_name, systems, output_dir, to_persist=True, **_):\n",
    "\n",
    "    correlations = {}\n",
    "    for corr_method in (pearsonr, spearmanr, kendalltau):\n",
    "        result = _get_system_level_correlation(data, metrics, target_col, systems, corr_method)\n",
    "        correlations[corr_method.__name__] = result\n",
    "\n",
    "    correlations = pd.DataFrame(correlations)\n",
    "    if to_persist:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        correlations.reset_index().to_csv(f\"{output_dir}/{dataset_name}_system_corrs.csv\", index=0)\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f5d844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"target_rescaled\"\n",
    "DATASET_NAME = \"realsumm\"\n",
    "DATASET_DIR = \"../datasets/summ_data/REALSumm/quantile/regression\"\n",
    "\n",
    "dfs = []\n",
    "for split in (\"all\", \"train\", \"dev\", \"test\"):\n",
    "    df = pd.read_csv(f\"{DATASET_DIR}/{split}.rescaled_1_50.csv\")\n",
    "    for col in (\"bert_score_p\", \"bert_score_r\", \"bert_score_f\"):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda s: s.replace(\"tensor\", \"\")[1:-1]).apply(float)\n",
    "\n",
    "    dfs.append(df)\n",
    "    \n",
    "all_df, train_df, dev_df, test_df = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0572aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Computing correlations for AUTOMATED METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "Computing pearsonr with target_rescaled col\n",
      "Computing spearmanr with target_rescaled col\n",
      "Computing kendalltau with target_rescaled col\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    # BERTScore\n",
    "    'bert_score_p','bert_score_r','bert_score_f',\n",
    "    'mover_score',\n",
    "    # PRISM\n",
    "    'prism_ref_hypo','prism_hypo_ref','prism_avg','prism_src_hypo',\n",
    "    # ROUGE\n",
    "    'rouge1_r','rouge1_p','rouge1_f',\n",
    "    'rouge2_r','rouge2_p','rouge2_f',\n",
    "    'rougel_r','rougel_p','rougel_f',\n",
    "    # BARTScore\n",
    "    'bart_score_cnn_ref_hypo_en', 'bart_score_cnn_ref_hypo_de',\n",
    "    'bart_score_cnn_hypo_ref_en','bart_score_cnn_hypo_ref_de',\n",
    "    'bart_score_cnn_avg_f_en','bart_score_cnn_avg_f_de',\n",
    "    'bart_score_cnn_harm_f_en','bart_score_cnn_harm_f_de',\n",
    "    'bart_score_src_hypo','bart_score_hypo_ref','bart_score_ref_hypo','bart_score_avg_f','bart_score_harm_f',\n",
    "    'bart_score_cnn_src_hypo','bart_score_cnn_hypo_ref','bart_score_cnn_ref_hypo','bart_score_cnn_avg_f','bart_score_cnn_harm_f',\n",
    "    'bart_score_para_src_hypo','bart_score_para_hypo_ref','bart_score_para_ref_hypo','bart_score_para_avg_f','bart_score_para_harm_f',\n",
    "]\n",
    "systems = sorted(all_df[\"sys_name\"].unique())\n",
    "\n",
    "instance_baseline_corrs = []\n",
    "system_baseline_corrs = []\n",
    "        \n",
    "print(\"-\" * 80)\n",
    "print(\"Computing correlations for AUTOMATED METRICS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "instance_corr_metrics = compute_instance_level_correlations(\n",
    "    dev_df,\n",
    "    metrics=METRICS,\n",
    "    target_col=TARGET_COL,\n",
    "    dataset_name=f\"{DATASET_NAME.lower()}\",\n",
    "    output_dir=\"\",\n",
    "    to_persist=False,\n",
    ")\n",
    "\n",
    "system_corr_metrics = compute_system_level_correlations(\n",
    "    dev_df, \n",
    "    metrics=METRICS,\n",
    "    target_col=TARGET_COL,\n",
    "    dataset_name=f\"{DATASET_NAME.lower()}\",\n",
    "    output_dir=\"\",\n",
    "    systems=systems,\n",
    "    to_persist=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e256b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template(name):\n",
    "    template_no = name.rpartition(\"_\")[-1]\n",
    "    return template_no\n",
    "    \n",
    "\n",
    "def extract_basename(name):\n",
    "    index = name.index(\"_template\")\n",
    "    return name[:index]\n",
    "\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "    from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_digits = 0\n",
    "    errs_p, errs_t, errs, mae, mse = [], [], [], [], []\n",
    "    for p, t in zip(df[\"prediction\"], df[\"label\"]):\n",
    "        # label is already a number\n",
    "        p = str(p) if isinstance(p, (int, float)) else p\n",
    "        p = p.strip()\n",
    "\n",
    "        num_correct += (p == str(t))\n",
    "        num_digits += p.isdigit()\n",
    "\n",
    "        if not p.isdigit():\n",
    "            continue\n",
    "\n",
    "        p, t = float(p), float(t)\n",
    "        err = (t - p)\n",
    "        errs_p.append(p)\n",
    "        errs_t.append(t)\n",
    "        errs.append(err)\n",
    "        mae.append(np.abs(err))\n",
    "        mse.append(err * err)\n",
    "    \n",
    "    metrics[\"accuracy\"] = num_correct / len(df)\n",
    "    metrics[\"digits_count\"] = num_digits\n",
    "    metrics[\"digits_pct\"] = num_digits / len(df)\n",
    "\n",
    "    metrics[\"err_len\"] = len(errs)\n",
    "    metrics[\"err_avg\"] = float(np.mean(errs))\n",
    "    metrics[\"mae_avg\"] = float(np.mean(mae))\n",
    "    metrics[\"mse_avg\"] = float(np.mean(mse))\n",
    "\n",
    "    metrics[\"err_std\"] = float(np.std(errs))\n",
    "    metrics[\"mae_std\"] = float(np.std(mae))\n",
    "    metrics[\"mse_std\"] = float(np.std(mse))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdaec87e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 experiments!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>digits_count</th>\n",
       "      <th>digits_pct</th>\n",
       "      <th>err_len</th>\n",
       "      <th>err_avg</th>\n",
       "      <th>mae_avg</th>\n",
       "      <th>mse_avg</th>\n",
       "      <th>err_std</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>baseline</th>\n",
       "      <th>eval_template</th>\n",
       "      <th>basename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070833</td>\n",
       "      <td>720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720</td>\n",
       "      <td>-1.227778</td>\n",
       "      <td>8.216667</td>\n",
       "      <td>111.397222</td>\n",
       "      <td>10.482833</td>\n",
       "      <td>6.624471</td>\n",
       "      <td>182.863217</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101389</td>\n",
       "      <td>720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720</td>\n",
       "      <td>-0.690278</td>\n",
       "      <td>8.012500</td>\n",
       "      <td>118.537500</td>\n",
       "      <td>10.865589</td>\n",
       "      <td>7.371387</td>\n",
       "      <td>228.705995</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  digits_count  digits_pct  err_len   err_avg   mae_avg  \\\n",
       "0  0.070833           720         1.0      720 -1.227778  8.216667   \n",
       "1  0.101389           720         1.0      720 -0.690278  8.012500   \n",
       "\n",
       "      mse_avg    err_std   mae_std     mse_std  \\\n",
       "0  111.397222  10.482833  6.624471  182.863217   \n",
       "1  118.537500  10.865589  7.371387  228.705995   \n",
       "\n",
       "                                            baseline eval_template  \\\n",
       "0  baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...             0   \n",
       "1  baseline__t5_3b_pretrain_ia3_without_ul_and_ln...             0   \n",
       "\n",
       "                                         basename  \n",
       "0        baseline__t5_3b_pretrain_10ksteps_no_ia3  \n",
       "1  baseline__t5_3b_pretrain_ia3_without_ul_and_ln  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = f\"../t-few-master/experiments_balanced_ft_t5/realsumm_reg/evals\"\n",
    "dev_files = sorted(glob(os.path.join(output_dir, \"*\", \"dev_pred.txt\")))\n",
    "print(f\"Found {len(dev_files)} experiments!\")\n",
    "print()\n",
    "\n",
    "def extract_name(path):\n",
    "    # Given a path in the format\n",
    "    # './t-few-master/exp_out/realsumm/t03b_realsumm_baseline_ft_train/<something>\n",
    "    # 1. Extract the parent dir `t03b_realsumm_baseline_ft_train`\n",
    "    exp_name = path.split(\"/\")[-2]\n",
    "\n",
    "    # 2. Keep all parts including baseline and afterwards\n",
    "    index_baseline = exp_name.index(\"baseline\")\n",
    "    return exp_name[index_baseline:]\n",
    "\n",
    "\n",
    "dev_data = {extract_name(path): pd.read_csv(path) for path in dev_files}\n",
    "\n",
    "# Before returning the dataframe, we will recover the bartscore_doc_id\n",
    "# to facilitate re-use of previous correlation methods.\n",
    "metrics_reg = []\n",
    "dev_baselines = {}\n",
    "for baseline, data in dev_data.items():\n",
    "    data = data.merge(dev_df, left_on=\"idx\", right_on=\"index\", suffixes=(None, \"_orig\"))\n",
    "    assert (data[\"label\"] == data[\"target_rescaled\"]).all()\n",
    "    \n",
    "    m = compute_metrics(data)\n",
    "    m[\"baseline\"] = baseline\n",
    "    \n",
    "    metrics_reg.append(m)\n",
    "    \n",
    "    data[\"is_digit_prediction\"] = data[\"prediction\"].apply(lambda p: str(p).strip().isdigit())\n",
    "    dev_baselines[baseline] = data\n",
    "    \n",
    "    # \n",
    "    data[\"log.pred_score\"] = data[\"log.pred_score\"].apply(lambda s: -1 * s)\n",
    "    data[\"log.label\"] = data[\"log.label\"].apply(lambda s: -1 * s)\n",
    "\n",
    "metrics_reg = pd.DataFrame(metrics_reg)\n",
    "metrics_reg[\"eval_template\"] = metrics_reg[\"baseline\"].apply(extract_template)\n",
    "metrics_reg[\"basename\"] = metrics_reg[\"baseline\"].apply(extract_basename)\n",
    "metrics_reg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce89904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Computing correlations for baseline__t5_3b_pretrain_10ksteps_no_ia3_template_0\n",
      "--------------------------------------------------------------------------------\n",
      "Computing pearsonr with target_rescaled col\n",
      "Computing spearmanr with target_rescaled col\n",
      "Computing kendalltau with target_rescaled col\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Computing correlations for baseline__t5_3b_pretrain_ia3_without_ul_and_ln_template_0\n",
      "--------------------------------------------------------------------------------\n",
      "Computing pearsonr with target_rescaled col\n",
      "Computing spearmanr with target_rescaled col\n",
      "Computing kendalltau with target_rescaled col\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"realsumm\"\n",
    "# target_col = \"litepyramid_recall\"\n",
    "target_col = \"target_rescaled\"\n",
    "split_baselines = dev_baselines\n",
    "systems = sorted(data[\"sys_name\"].unique())\n",
    "\n",
    "instance_baseline_corrs = []\n",
    "system_baseline_corrs = []\n",
    "        \n",
    "for baseline, data in split_baselines.items():\n",
    "    if data[\"is_digit_prediction\"].all():\n",
    "        \n",
    "        print(\"\\n\" * 4)\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Computing correlations for\", baseline)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        instance_corr = compute_instance_level_correlations(\n",
    "            data,\n",
    "            metrics=[\"prediction\"],\n",
    "            target_col=target_col,\n",
    "            dataset_name=f\"{dataset_name.lower()}_{baseline}\",\n",
    "            output_dir=\"\",\n",
    "            to_persist=False,\n",
    "        )\n",
    "\n",
    "        system_corr = compute_system_level_correlations(\n",
    "            data, \n",
    "            metrics=[\"prediction\"],\n",
    "            target_col=target_col,\n",
    "            dataset_name=f\"{dataset_name.lower()}_{baseline}\",\n",
    "            output_dir=\"\",\n",
    "            systems=systems,\n",
    "            to_persist=False\n",
    "        )\n",
    "\n",
    "        instance_corr[\"index\"] = baseline\n",
    "        system_corr[\"index\"] = baseline\n",
    "\n",
    "        instance_baseline_corrs.append(instance_corr)\n",
    "        system_baseline_corrs.append(system_corr)\n",
    "\n",
    "instance_baseline_corrs = pd.concat(instance_baseline_corrs)\n",
    "system_baseline_corrs = pd.concat(system_baseline_corrs)\n",
    "\n",
    "instance_baseline_corrs[\"eval_template\"] = instance_baseline_corrs[\"index\"].apply(extract_template)\n",
    "instance_baseline_corrs[\"basename\"] = instance_baseline_corrs[\"index\"].apply(extract_basename)\n",
    "\n",
    "system_baseline_corrs[\"eval_template\"] = system_baseline_corrs[\"index\"].apply(extract_template)\n",
    "system_baseline_corrs[\"basename\"] = system_baseline_corrs[\"index\"].apply(extract_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ce3be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearsonr</th>\n",
       "      <th>spearmanr</th>\n",
       "      <th>kendalltau</th>\n",
       "      <th>index</th>\n",
       "      <th>eval_template</th>\n",
       "      <th>basename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>0.338668</td>\n",
       "      <td>0.349662</td>\n",
       "      <td>0.29334</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>0.285011</td>\n",
       "      <td>0.265968</td>\n",
       "      <td>0.22961</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pearsonr  spearmanr  kendalltau  \\\n",
       "prediction  0.338668   0.349662     0.29334   \n",
       "prediction  0.285011   0.265968     0.22961   \n",
       "\n",
       "                                                        index eval_template  \\\n",
       "prediction  baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...             0   \n",
       "prediction  baseline__t5_3b_pretrain_ia3_without_ul_and_ln...             0   \n",
       "\n",
       "                                                  basename  \n",
       "prediction        baseline__t5_3b_pretrain_10ksteps_no_ia3  \n",
       "prediction  baseline__t5_3b_pretrain_ia3_without_ul_and_ln  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_baseline_corrs.sort_values(\"kendalltau\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64099b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearsonr</th>\n",
       "      <th>spearmanr</th>\n",
       "      <th>kendalltau</th>\n",
       "      <th>index</th>\n",
       "      <th>eval_template</th>\n",
       "      <th>basename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_10ksteps_no_ia3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln...</td>\n",
       "      <td>0</td>\n",
       "      <td>baseline__t5_3b_pretrain_ia3_without_ul_and_ln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pearsonr  spearmanr  kendalltau  \\\n",
       "prediction    0.7389     0.6920      0.5236   \n",
       "prediction    0.7033     0.6359      0.4582   \n",
       "\n",
       "                                                        index eval_template  \\\n",
       "prediction  baseline__t5_3b_pretrain_10ksteps_no_ia3_templ...             0   \n",
       "prediction  baseline__t5_3b_pretrain_ia3_without_ul_and_ln...             0   \n",
       "\n",
       "                                                  basename  \n",
       "prediction        baseline__t5_3b_pretrain_10ksteps_no_ia3  \n",
       "prediction  baseline__t5_3b_pretrain_ia3_without_ul_and_ln  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_baseline_corrs.sort_values(\"kendalltau\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3f2a2",
   "metadata": {},
   "source": [
    "## Easy examples \n",
    "\n",
    "TODO LIST\n",
    "- [ ] Find examples that have a wide spread of scores (higher standard deviation)\n",
    "- [ ] Discern whether T5 (fully trained) is capable of assigning different scores to the different outputs. Are these contradicting? How difficult is the task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "606f59e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>log.pred_score</th>\n",
       "      <th>log.label</th>\n",
       "      <th>num_truncated</th>\n",
       "      <th>top5_unconstrained</th>\n",
       "      <th>top5_constrained</th>\n",
       "      <th>current_epoch</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>bart_score_cnn_avg_f_en</th>\n",
       "      <th>bart_score_cnn_avg_f_de</th>\n",
       "      <th>bart_score_cnn_harm_f_en</th>\n",
       "      <th>bart_score_cnn_harm_f_de</th>\n",
       "      <th>target</th>\n",
       "      <th>bin</th>\n",
       "      <th>label_orig</th>\n",
       "      <th>discretization_type</th>\n",
       "      <th>target_rescaled</th>\n",
       "      <th>is_digit_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.754195</td>\n",
       "      <td>-7.379195</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['▁34', '▁22', '▁32', '▁26', '▁23']...</td>\n",
       "      <td>{'tokens': ['▁34', '▁22', '▁32', '▁26', '▁23']...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142573</td>\n",
       "      <td>-3.338079</td>\n",
       "      <td>-1.568310</td>\n",
       "      <td>-1.667924</td>\n",
       "      <td>36</td>\n",
       "      <td>(30.62, 42.86]</td>\n",
       "      <td>1</td>\n",
       "      <td>5-quantile</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.492056</td>\n",
       "      <td>-21.132681</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['▁22', '▁35', '▁34', '▁32', '▁23']...</td>\n",
       "      <td>{'tokens': ['▁22', '▁35', '▁34', '▁32', '▁23']...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.299922</td>\n",
       "      <td>-3.506089</td>\n",
       "      <td>-1.584143</td>\n",
       "      <td>-1.704337</td>\n",
       "      <td>29</td>\n",
       "      <td>(-0.01, 30.62]</td>\n",
       "      <td>0</td>\n",
       "      <td>5-quantile</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.020732</td>\n",
       "      <td>-23.083233</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['▁34', '▁28', '▁38', '▁29', '▁17']...</td>\n",
       "      <td>{'tokens': ['▁34', '▁28', '▁38', '▁29', '▁17']...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.587052</td>\n",
       "      <td>-2.798319</td>\n",
       "      <td>-1.276288</td>\n",
       "      <td>-1.391062</td>\n",
       "      <td>79</td>\n",
       "      <td>(62.5, 100.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>5-quantile</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-20.347918</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['▁34', '▁28', '▁17', '▁35', '▁23']...</td>\n",
       "      <td>{'tokens': ['▁34', '▁28', '▁17', '▁35', '▁23']...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.879158</td>\n",
       "      <td>-3.100711</td>\n",
       "      <td>-1.435252</td>\n",
       "      <td>-1.547302</td>\n",
       "      <td>43</td>\n",
       "      <td>(30.62, 42.86]</td>\n",
       "      <td>1</td>\n",
       "      <td>5-quantile</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.486572</td>\n",
       "      <td>-29.486572</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['▁17', '▁26', '▁22', '▁16', '▁19']...</td>\n",
       "      <td>{'tokens': ['▁17', '▁26', '▁22', '▁16', '▁19']...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.287043</td>\n",
       "      <td>-3.518617</td>\n",
       "      <td>-1.643086</td>\n",
       "      <td>-1.758646</td>\n",
       "      <td>14</td>\n",
       "      <td>(-0.01, 30.62]</td>\n",
       "      <td>0</td>\n",
       "      <td>5-quantile</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label  prediction  log.pred_score  log.label  num_truncated  \\\n",
       "0    0     19          34       -0.754195  -7.379195              0   \n",
       "1    1     15          22       -0.492056 -21.132681              0   \n",
       "2    2     40          34       -0.020732 -23.083233              0   \n",
       "3    3     22          34       -0.004167 -20.347918              0   \n",
       "4    4      8          17       -0.486572 -29.486572              0   \n",
       "\n",
       "                                  top5_unconstrained  \\\n",
       "0  {'tokens': ['▁34', '▁22', '▁32', '▁26', '▁23']...   \n",
       "1  {'tokens': ['▁22', '▁35', '▁34', '▁32', '▁23']...   \n",
       "2  {'tokens': ['▁34', '▁28', '▁38', '▁29', '▁17']...   \n",
       "3  {'tokens': ['▁34', '▁28', '▁17', '▁35', '▁23']...   \n",
       "4  {'tokens': ['▁17', '▁26', '▁22', '▁16', '▁19']...   \n",
       "\n",
       "                                    top5_constrained  current_epoch  index  \\\n",
       "0  {'tokens': ['▁34', '▁22', '▁32', '▁26', '▁23']...              0      0   \n",
       "1  {'tokens': ['▁22', '▁35', '▁34', '▁32', '▁23']...              0      1   \n",
       "2  {'tokens': ['▁34', '▁28', '▁38', '▁29', '▁17']...              0      2   \n",
       "3  {'tokens': ['▁34', '▁28', '▁17', '▁35', '▁23']...              0      3   \n",
       "4  {'tokens': ['▁17', '▁26', '▁22', '▁16', '▁19']...              0      4   \n",
       "\n",
       "   ...  bart_score_cnn_avg_f_en bart_score_cnn_avg_f_de  \\\n",
       "0  ...                -3.142573               -3.338079   \n",
       "1  ...                -3.299922               -3.506089   \n",
       "2  ...                -2.587052               -2.798319   \n",
       "3  ...                -2.879158               -3.100711   \n",
       "4  ...                -3.287043               -3.518617   \n",
       "\n",
       "  bart_score_cnn_harm_f_en bart_score_cnn_harm_f_de target             bin  \\\n",
       "0                -1.568310                -1.667924     36  (30.62, 42.86]   \n",
       "1                -1.584143                -1.704337     29  (-0.01, 30.62]   \n",
       "2                -1.276288                -1.391062     79   (62.5, 100.0]   \n",
       "3                -1.435252                -1.547302     43  (30.62, 42.86]   \n",
       "4                -1.643086                -1.758646     14  (-0.01, 30.62]   \n",
       "\n",
       "   label_orig  discretization_type  target_rescaled  is_digit_prediction  \n",
       "0           1           5-quantile               19                 True  \n",
       "1           0           5-quantile               15                 True  \n",
       "2           4           5-quantile               40                 True  \n",
       "3           1           5-quantile               22                 True  \n",
       "4           0           5-quantile                8                 True  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_dev_preds = split_baselines[\"baseline__t5_3b_pretrain_10ksteps_no_ia3_template_0\"]\n",
    "t5_dev_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d397b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less ambiguous Bartscore doc ids: [94, 68, 91, 42, 48]\n",
      "More ambiguous Bartscore doc ids: [63, 26, 27, 45, 96]\n",
      "Less ambiguous Bartscore doc ids: [88, 22, 35, 42, 26]\n",
      "More ambiguous Bartscore doc ids: [16, 6, 91, 48, 68]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_rescaled</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target_rescaled</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>-0.177011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target_rescaled  prediction\n",
       "target_rescaled         1.000000   -0.177011\n",
       "prediction             -0.177011    1.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bartscore_doc_id uniquely identifies each document id \n",
    "scores_human_std = t5_dev_preds.groupby(\"bartscore_doc_id\").std()[\"target_rescaled\"].sort_values()\n",
    "low_human_std_top5 = scores_human_std.head().index.tolist()\n",
    "high_human_std_top5 = scores_human_std.tail().index.tolist()\n",
    "print(\"Less ambiguous Bartscore doc ids:\", low_human_std_top5)\n",
    "print(\"More ambiguous Bartscore doc ids:\", high_human_std_top5)\n",
    "\n",
    "# bartscore_doc_id uniquely identifies each document id \n",
    "scores_model_std = t5_dev_preds.groupby(\"bartscore_doc_id\").std()[\"prediction\"].sort_values()\n",
    "low_model_std_top5 = scores_model_std.head().index.tolist()\n",
    "high_model_std_top5 = scores_model_std.tail().index.tolist()\n",
    "\n",
    "print(\"Less ambiguous Bartscore doc ids:\", low_model_std_top5)\n",
    "print(\"More ambiguous Bartscore doc ids:\", high_model_std_top5)\n",
    "\n",
    "# We can observe that in general the variability in model is minimal anti-correlated with human's variability\n",
    "t5_dev_preds.groupby(\"bartscore_doc_id\").std()[[\"target_rescaled\", \"prediction\"]].corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8be9c",
   "metadata": {},
   "source": [
    "let's check this for other metrics as a proxy measure of its goodness. We can see below, the best metrics are:\n",
    "- PRISM (avg);\n",
    "- ROUGE-L (recall variant)\n",
    "- BartScore CNN (hypothesis -> ref)\n",
    "\n",
    "This is interesting because these top 5 metrics are not (for the most part) the ones that achieve the highest summary-level correlation coefficients (avg instance-wise correlation). The ones achieving higher instance-level results are: \n",
    "- rouge1_r\n",
    "- rougel_r\n",
    "- bart_score_para_hypo_ref\n",
    "- bart_score_cnn_hypo_ref_de\n",
    "- bert_score_r\t\n",
    "\n",
    "Note however, that the STD does not tell us nothing about the ranking itself, it just gives an idea of how spread off the predicted values are. In particular, the fact that PRISM has a better correlation in terms of the STD means that it \"agrees more often in the uncertainty\" of the examples. The highest value is 0.22 which does not entail very strong correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb37f8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_rescaled</th>\n",
       "      <th>bert_score_p</th>\n",
       "      <th>bert_score_r</th>\n",
       "      <th>bert_score_f</th>\n",
       "      <th>mover_score</th>\n",
       "      <th>prism_ref_hypo</th>\n",
       "      <th>prism_hypo_ref</th>\n",
       "      <th>prism_avg</th>\n",
       "      <th>prism_src_hypo</th>\n",
       "      <th>rouge1_r</th>\n",
       "      <th>...</th>\n",
       "      <th>bart_score_cnn_src_hypo</th>\n",
       "      <th>bart_score_cnn_hypo_ref</th>\n",
       "      <th>bart_score_cnn_ref_hypo</th>\n",
       "      <th>bart_score_cnn_avg_f</th>\n",
       "      <th>bart_score_cnn_harm_f</th>\n",
       "      <th>bart_score_para_src_hypo</th>\n",
       "      <th>bart_score_para_hypo_ref</th>\n",
       "      <th>bart_score_para_ref_hypo</th>\n",
       "      <th>bart_score_para_avg_f</th>\n",
       "      <th>bart_score_para_harm_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target_rescaled</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080460</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.071264</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.154023</td>\n",
       "      <td>0.227586</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.163218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094253</td>\n",
       "      <td>0.190805</td>\n",
       "      <td>0.052874</td>\n",
       "      <td>0.121839</td>\n",
       "      <td>0.177011</td>\n",
       "      <td>-0.025287</td>\n",
       "      <td>0.154023</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.154023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prism_avg</th>\n",
       "      <td>0.227586</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.420690</td>\n",
       "      <td>0.439080</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.452874</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.209195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043678</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.255172</td>\n",
       "      <td>0.397701</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.025287</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.512644</td>\n",
       "      <td>0.512644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougel_r</th>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.085057</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.521839</td>\n",
       "      <td>-0.016092</td>\n",
       "      <td>0.439080</td>\n",
       "      <td>0.301149</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.770115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131034</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>-0.075862</td>\n",
       "      <td>0.075862</td>\n",
       "      <td>0.140230</td>\n",
       "      <td>-0.052874</td>\n",
       "      <td>0.420690</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>0.154023</td>\n",
       "      <td>0.163218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart_score_cnn_hypo_ref</th>\n",
       "      <td>0.190805</td>\n",
       "      <td>0.177011</td>\n",
       "      <td>0.328736</td>\n",
       "      <td>0.245977</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>-0.071264</td>\n",
       "      <td>0.512644</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>-0.029885</td>\n",
       "      <td>0.429885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112644</td>\n",
       "      <td>0.250575</td>\n",
       "      <td>0.370115</td>\n",
       "      <td>-0.126437</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart_score_cnn_hypo_ref_en</th>\n",
       "      <td>0.186207</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.342529</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.406897</td>\n",
       "      <td>-0.085057</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>-0.025287</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098851</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>-0.126437</td>\n",
       "      <td>0.236782</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>-0.121839</td>\n",
       "      <td>0.554023</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>0.278161</td>\n",
       "      <td>0.296552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            target_rescaled  bert_score_p  bert_score_r  \\\n",
       "target_rescaled                    1.000000     -0.080460     -0.066667   \n",
       "prism_avg                          0.227586      0.287356      0.420690   \n",
       "rougel_r                           0.218391      0.085057      0.282759   \n",
       "bart_score_cnn_hypo_ref            0.190805      0.177011      0.328736   \n",
       "bart_score_cnn_hypo_ref_en         0.186207      0.172414      0.342529   \n",
       "\n",
       "                            bert_score_f  mover_score  prism_ref_hypo  \\\n",
       "target_rescaled                -0.057471     0.071264        0.103448   \n",
       "prism_avg                       0.439080     0.448276        0.452874   \n",
       "rougel_r                        0.126437     0.521839       -0.016092   \n",
       "bart_score_cnn_hypo_ref         0.245977     0.402299       -0.071264   \n",
       "bart_score_cnn_hypo_ref_en      0.241379     0.406897       -0.085057   \n",
       "\n",
       "                            prism_hypo_ref  prism_avg  prism_src_hypo  \\\n",
       "target_rescaled                   0.154023   0.227586        0.025287   \n",
       "prism_avg                         0.632184   1.000000        0.034483   \n",
       "rougel_r                          0.439080   0.301149        0.117241   \n",
       "bart_score_cnn_hypo_ref           0.512644   0.310345       -0.029885   \n",
       "bart_score_cnn_hypo_ref_en        0.517241   0.296552       -0.025287   \n",
       "\n",
       "                            rouge1_r  ...  bart_score_cnn_src_hypo  \\\n",
       "target_rescaled             0.163218  ...                -0.094253   \n",
       "prism_avg                   0.209195  ...                 0.043678   \n",
       "rougel_r                    0.770115  ...                -0.131034   \n",
       "bart_score_cnn_hypo_ref     0.429885  ...                -0.094253   \n",
       "bart_score_cnn_hypo_ref_en  0.443678  ...                -0.098851   \n",
       "\n",
       "                            bart_score_cnn_hypo_ref  bart_score_cnn_ref_hypo  \\\n",
       "target_rescaled                            0.190805                 0.052874   \n",
       "prism_avg                                  0.310345                 0.255172   \n",
       "rougel_r                                   0.448276                -0.075862   \n",
       "bart_score_cnn_hypo_ref                    1.000000                -0.112644   \n",
       "bart_score_cnn_hypo_ref_en                 0.986207                -0.126437   \n",
       "\n",
       "                            bart_score_cnn_avg_f  bart_score_cnn_harm_f  \\\n",
       "target_rescaled                         0.121839               0.177011   \n",
       "prism_avg                               0.397701               0.379310   \n",
       "rougel_r                                0.075862               0.140230   \n",
       "bart_score_cnn_hypo_ref                 0.250575               0.370115   \n",
       "bart_score_cnn_hypo_ref_en              0.236782               0.356322   \n",
       "\n",
       "                            bart_score_para_src_hypo  \\\n",
       "target_rescaled                            -0.025287   \n",
       "prism_avg                                  -0.025287   \n",
       "rougel_r                                   -0.052874   \n",
       "bart_score_cnn_hypo_ref                    -0.126437   \n",
       "bart_score_cnn_hypo_ref_en                 -0.121839   \n",
       "\n",
       "                            bart_score_para_hypo_ref  \\\n",
       "target_rescaled                             0.154023   \n",
       "prism_avg                                   0.393103   \n",
       "rougel_r                                    0.420690   \n",
       "bart_score_cnn_hypo_ref                     0.540230   \n",
       "bart_score_cnn_hypo_ref_en                  0.554023   \n",
       "\n",
       "                            bart_score_para_ref_hypo  bart_score_para_avg_f  \\\n",
       "target_rescaled                             0.006897               0.172414   \n",
       "prism_avg                                   0.356322               0.512644   \n",
       "rougel_r                                   -0.048276               0.154023   \n",
       "bart_score_cnn_hypo_ref                    -0.002299               0.282759   \n",
       "bart_score_cnn_hypo_ref_en                 -0.006897               0.278161   \n",
       "\n",
       "                            bart_score_para_harm_f  \n",
       "target_rescaled                           0.154023  \n",
       "prism_avg                                 0.512644  \n",
       "rougel_r                                  0.163218  \n",
       "bart_score_cnn_hypo_ref                   0.310345  \n",
       "bart_score_cnn_hypo_ref_en                0.296552  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_dev_preds.groupby(\"bartscore_doc_id\").std()[[\"target_rescaled\"] + METRICS].corr(method=\"kendall\").sort_values(\"target_rescaled\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711c8c5",
   "metadata": {},
   "source": [
    "### Analysis 1: High Human STD \n",
    "\n",
    "Check out the top 5 examples that lead to the most std between scores, i.e., the easiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814a7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
